{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnchorBoxes(layer):\n",
    "        '''Input shape:\n",
    "        4D tensor of shape `(batch, channels, height, width)` if `dim_ordering = 'th'`\n",
    "        or `(batch, height, width, channels)` if `dim_ordering = 'tf'`.\n",
    "    Output shape:\n",
    "        5D tensor of shape `(batch, height, width, n_boxes, 8)`. The last axis contains\n",
    "        the four anchor box coordinates and the four variance values for each box.\n",
    "    '''\n",
    "        \n",
    "        def __ini__(self,\n",
    "                   img_height,\n",
    "                   img_width,\n",
    "                   this_scale,\n",
    "                   next_scale,\n",
    "                   aspect_ratios=[0.5,1.0,2.0],\n",
    "                   two_boxes_for_ar1,\n",
    "                   this_steps=None,\n",
    "                   this_offsets=None,\n",
    "                    #clip_boxes=False,\n",
    "                    #variances=[0.1,0.1,0.2,0.2]\n",
    "                    #coords='centroids',\n",
    "                    #normalize_coords=False,\n",
    "                    **kwargs)\n",
    "            self.img_height = img_height\n",
    "            self.img_width = img_width\n",
    "            self.this_scale = this_scale\n",
    "            self.next_scale = next_scale\n",
    "            self.aspect_ratios = aspect_ratios\n",
    "            self.two_boxes_for_ar1 = two_boxes_for_ar1\n",
    "            self.this_steps = this_steps\n",
    "            self.this_offsets = this_offsets\n",
    "#             self.clip_boxes = clip_boxes\n",
    "#             self.variances = variances\n",
    "#             self.coords = coords\n",
    "#             self.normalize_coords = normalize_coords\n",
    "\n",
    "\n",
    "            # Compute box width and height for each aspect ratio\n",
    "            # The shorter side of the image will be used to compute `w` and `h` using `scale` and `aspect_ratios`.\n",
    "\n",
    "            size=min(self.img_width,self.img_height)\n",
    "            \n",
    "            wh_list=[]\n",
    "            \n",
    "            for ar in self.aspect_ratios:\n",
    "                if (ar == 1):\n",
    "                    \n",
    "                    # Compute the regular anchor box for aspect ratio 1.\n",
    "                    box_height=box_width=self.this_scale*size\n",
    "                    \n",
    "                    wh_list.append((box_width,box_height))\n",
    "                    \n",
    "                    if.self_boxes_for_ar1:\n",
    "                        \n",
    "                        # Compute one slightly larger version using the geometric mean of this scale value and the next.\n",
    "                        box_height=box_width=np.sqrt(self.this_scale*self.next_scale)*size \n",
    "                        \n",
    "                        wh_list.append((box_width,box_height))\n",
    "                        \n",
    "                else:\n",
    "                    box_height=self.this_scale*size/np.sqrt(ar)\n",
    "                    \n",
    "                    box_width=self.this_scale*np.sqrt(ar)*size\n",
    "                    \n",
    "                    wh_list((box_width,box_height))\n",
    "                    \n",
    "            wh_list=np.array(wh_list)\n",
    "            \n",
    "             # We need the shape of the input tensor!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "                \n",
    "#             if K.image_dim_ordering() == 'tf':\n",
    "#             batch_size, feature_map_height, feature_map_width, feature_map_channels = x._keras_shape\n",
    "#             else: # Not yet relevant since TensorFlow is the only supported backend right now, but it can't harm to have this in here for the future\n",
    "#             batch_size, feature_map_channels, feature_map_height, feature_map_width = x._keras_shape  \n",
    "                \n",
    "             # We need the shape of the input tensor!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "            \n",
    "             # Compute the grid of box center points. They are identical for all aspect ratios.\n",
    "            \n",
    "             # Compute the step sizes, i.e. how far apart the anchor box center points will be vertically and horizontally.\n",
    "                \n",
    "            if (self.this_steps is None):\n",
    "                \n",
    "                step_height=self.img_height / feature_map_height\n",
    "                \n",
    "                step_width=self.img_width / feature_map_width\n",
    "                \n",
    "            else:\n",
    "                \n",
    "                if isinstance(self.this_steps,(list,tuple)) and (len(self.this_steps) == 2):\n",
    "                    \n",
    "                    step_height=self.this_steps[0]\n",
    "                    \n",
    "                    step_width=self.this_steps[1]\n",
    "                    \n",
    "                elif isinstance(self.this_steps,(int,float)):\n",
    "                    \n",
    "                    step_height=self.this_steps\n",
    "                    \n",
    "                    step_width=self.this_steps\n",
    "                    \n",
    "            # Compute the offsets, i.e. at what pixel values the first anchor box center point will be from the top and from the left of the image.    \n",
    "                    \n",
    "            if (self.this_offsets is None):\n",
    "                \n",
    "                offset_height=0.5\n",
    "                \n",
    "                offset_width=0.5\n",
    "                \n",
    "            else:\n",
    "                \n",
    "                if isinstance(self.this_offsets,(list,tuple)) and (len(self.this_offsets)==2):\n",
    "                    \n",
    "                    offset_height=self.this_offsets[0]\n",
    "                    \n",
    "                    offset_width=self.this_offsets[1]\n",
    "                    \n",
    "                elif isinstance(self.this_steps,(int,float)):\n",
    "                    \n",
    "                    step_height=self.this_steps\n",
    "                    \n",
    "                    step_width=self.this_steps\n",
    "                    \n",
    "            # Now that we have the offsets and step sizes, compute the grid of anchor box center points.\n",
    "                    \n",
    "            cy=np.linspace(offset_height*step_height,(offset_height+feature_map_height -1)*step_height,feature_map_height)\n",
    "                \n",
    "            cx=np.linspace(offset_width*step_width,(offset_width+feature_map_width -1)*step_width,feature_map_width)\n",
    "            \n",
    "            cx_grid,cy_grid=np.meshgrid(cx,cy)\n",
    "            \n",
    "            cx_grid = np.expand_dims(cx_grid, -1) # This is necessary for np.tile() to do what we want further down\n",
    "            \n",
    "            cy_grid = np.expand_dims(cy_grid, -1) # This is necessary for np.tile() to do what we want further down\n",
    "            \n",
    "            # Create a 4D tensor template of shape `(feature_map_height, feature_map_width, n_boxes, 4)`\n",
    "            # where the last dimension will contain `(cx, cy, w, h)`\n",
    "            \n",
    "            boxes_tensor=np.zeros((feature_map_height,feature_map_width,self.n_boxes,4))\n",
    "            \n",
    "            #Понято не до конца\n",
    "            #смотри np.tile переводит измерение к нужной длине\n",
    "            boxes_tensor[:, :, :, 0] = np.tile(cx_grid, (1, 1, self.n_boxes)) # Set cx\n",
    "            boxes_tensor[:, :, :, 1] = np.tile(cy_grid, (1, 1, self.n_boxes)) # Set cy\n",
    "            boxes_tensor[:, :, :, 2] = wh_list[:, 0] # Set w\n",
    "            boxes_tensor[:, :, :, 3] = wh_list[:, 1] # Set h\n",
    "            #Понято не до конца\n",
    "            \n",
    "            # Convert `(cx, cy, w, h)` to `(xmin, xmax, ymin, ymax)`\n",
    "            boxes_tensor = convert_coordinates(boxes_tensor, start_index=0, conversion='centroids2corners')\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.linspace(0,100,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=np.linspace(0,1000,11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "cx,cy=np.meshgrid(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 8)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "cx_grid = np.expand_dims(cx, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 8, 1)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cx_grid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=np.tile(cx_grid,(1,1,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 8)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[:,:,0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "m=np.array([[1,2,3],[4,5,6],[7,8,9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=np.array([0,1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 2, 0, 1, 2]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.tile(a,(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes_tensor=np.zeros((300,300,10,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 300, 10, 4)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boxes_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 300, 10)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boxes_tensor[:,:,:,0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes_tensor[:, :, :, 0] = np.tile(cx_grid, (1, 1, self.n_boxes))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
