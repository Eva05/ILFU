{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnchorBoxes():\n",
    "    \n",
    "        '''Input shape:\n",
    "        4D tensor of shape `(batch, channels, height, width)` if `dim_ordering = 'th'`\n",
    "        or `(batch, height, width, channels)` if `dim_ordering = 'tf'`.\n",
    "    Output shape:\n",
    "        5D tensor of shape `(batch, height, width, n_boxes, 8)`. The last axis contains\n",
    "        the four anchor box coordinates and the four variance values for each box.\n",
    "    '''\n",
    "        \n",
    "        def __ini__(self,\n",
    "                   img_height,\n",
    "                   img_width,\n",
    "                   this_scale,\n",
    "                   next_scale,\n",
    "                   aspect_ratios=[0.5,1.0,2.0],\n",
    "                   two_boxes_for_ar1=True,\n",
    "                   this_steps=None,\n",
    "                   this_offsets=None,\n",
    "                   clip_boxes=False,\n",
    "                   variances=[0.1,0.1,0.2,0.2],\n",
    "                   coords='centroids',\n",
    "                   normalize_coords=False,\n",
    "                **kwargs):\n",
    "\n",
    "\n",
    "            self.img_height = img_height\n",
    "            self.img_width = img_width\n",
    "            self.this_scale = this_scale\n",
    "            self.next_scale = next_scale\n",
    "            self.aspect_ratios = aspect_ratios\n",
    "            self.two_boxes_for_ar1 = two_boxes_for_ar1\n",
    "            self.this_steps = this_steps\n",
    "            self.this_offsets = this_offsets\n",
    "            self.clip_boxes = clip_boxes\n",
    "            self.variances = variances\n",
    "            self.coords = coords\n",
    "            self.normalize_coords = normalize_coords\n",
    "\n",
    "\n",
    "        # Compute box width and height for each aspect ratio\n",
    "        # The shorter side of the image will be used to compute `w` and `h` using `scale` and `aspect_ratios`.\n",
    "        \n",
    "        def call(self,x,mask=None):\n",
    "\n",
    "            size=min(self.img_width,self.img_height)\n",
    "\n",
    "            wh_list=[]\n",
    "\n",
    "            for ar in self.aspect_ratios:\n",
    "                if (ar == 1):\n",
    "\n",
    "                    # Compute the regular anchor box for aspect ratio 1.\n",
    "                    box_height=box_width=self.this_scale*size\n",
    "\n",
    "                    wh_list.append((box_width,box_height))\n",
    "\n",
    "                    if self_boxes_for_ar1:\n",
    "\n",
    "                        # Compute one slightly larger version using the geometric mean of this scale value and the next.\n",
    "                        box_height=box_width=np.sqrt(self.this_scale*self.next_scale)*size \n",
    "\n",
    "                        wh_list.append((box_width,box_height))\n",
    "\n",
    "                else:\n",
    "                    box_height=self.this_scale*size/np.sqrt(ar)\n",
    "\n",
    "                    box_width=self.this_scale*np.sqrt(ar)*size\n",
    "\n",
    "                    wh_list((box_width,box_height))\n",
    "\n",
    "            wh_list=np.array(wh_list)\n",
    "\n",
    "             # We need the shape of the input tensor!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "\n",
    "        #             if K.image_dim_ordering() == 'tf':\n",
    "        #             batch_size, feature_map_height, feature_map_width, feature_map_channels = x._keras_shape\n",
    "        #             else: # Not yet relevant since TensorFlow is the only supported backend right now, but it can't harm to have this in here for the future\n",
    "        #             batch_size, feature_map_channels, feature_map_height, feature_map_width = x._keras_shape  \n",
    "\n",
    "             # We need the shape of the input tensor!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "\n",
    "             # Compute the grid of box center points. They are identical for all aspect ratios.\n",
    "\n",
    "             # Compute the step sizes, i.e. how far apart the anchor box center points will be vertically and horizontally.\n",
    "\n",
    "            if (self.this_steps is None):\n",
    "\n",
    "                step_height=self.img_height / feature_map_height\n",
    "\n",
    "                step_width=self.img_width / feature_map_width\n",
    "\n",
    "            else:\n",
    "\n",
    "                if isinstance(self.this_steps,(list,tuple)) and (len(self.this_steps) == 2):\n",
    "\n",
    "                    step_height=self.this_steps[0]\n",
    "\n",
    "                    step_width=self.this_steps[1]\n",
    "\n",
    "                elif isinstance(self.this_steps,(int,float)):\n",
    "\n",
    "                    step_height=self.this_steps\n",
    "\n",
    "                    step_width=self.this_steps\n",
    "\n",
    "            # Compute the offsets, i.e. at what pixel values the first anchor box center point will be from the top and from the left of the image.    \n",
    "\n",
    "            if (self.this_offsets is None):\n",
    "\n",
    "                offset_height=0.5\n",
    "\n",
    "                offset_width=0.5\n",
    "\n",
    "            else:\n",
    "\n",
    "                if isinstance(self.this_offsets,(list,tuple)) and (len(self.this_offsets)==2):\n",
    "\n",
    "                    offset_height=self.this_offsets[0]\n",
    "\n",
    "                    offset_width=self.this_offsets[1]\n",
    "\n",
    "                elif isinstance(self.this_steps,(int,float)):\n",
    "\n",
    "                    step_height=self.this_steps\n",
    "\n",
    "                    step_width=self.this_steps\n",
    "\n",
    "            # Now that we have the offsets and step sizes, compute the grid of anchor box center points.\n",
    "\n",
    "            cy=np.linspace(offset_height*step_height,(offset_height+feature_map_height -1)*step_height,feature_map_height)\n",
    "\n",
    "            cx=np.linspace(offset_width*step_width,(offset_width+feature_map_width -1)*step_width,feature_map_width)\n",
    "\n",
    "            cx_grid,cy_grid=np.meshgrid(cx,cy)\n",
    "\n",
    "            cx_grid = np.expand_dims(cx_grid, -1) # This is necessary for np.tile() to do what we want further down\n",
    "\n",
    "            cy_grid = np.expand_dims(cy_grid, -1) # This is necessary for np.tile() to do what we want further down\n",
    "\n",
    "            # Create a 4D tensor template of shape `(feature_map_height, feature_map_width, n_boxes, 4)`\n",
    "            # where the last dimension will contain `(cx, cy, w, h)`\n",
    "\n",
    "            boxes_tensor=np.zeros((feature_map_height,feature_map_width,self.n_boxes,4))\n",
    "\n",
    "            #Понято не до конца\n",
    "            #смотри np.tile переводит измерение к нужной длине\n",
    "            boxes_tensor[:, :, :, 0] = np.tile(cx_grid, (1, 1, self.n_boxes)) # Set cx\n",
    "            boxes_tensor[:, :, :, 1] = np.tile(cy_grid, (1, 1, self.n_boxes)) # Set cy\n",
    "            boxes_tensor[:, :, :, 2] = wh_list[:, 0] # Set w\n",
    "            boxes_tensor[:, :, :, 3] = wh_list[:, 1] # Set h\n",
    "            #Понято не до конца\n",
    "\n",
    "            # Convert `(cx, cy, w, h)` to `(xmin, xmax, ymin, ymax)`\n",
    "            boxes_tensor = convert_coordinates(boxes_tensor, start_index=0, conversion='centroids2corners')\n",
    "\n",
    "            # If `clip_boxes` is enabled, clip the coordinates to lie within the image boundaries\n",
    "            #Смотрим чтобы Bbox не заходили за границы самого изображения\n",
    "            if self.clip_boxes:\n",
    "\n",
    "                x_coords=boxes_tensor[:,:,:,[0,2]]\n",
    "                x_coords[x_coords >= self.img_width]=self.img_widht-1\n",
    "                x_coords[x_coords<0]=0\n",
    "                boxes_tensor[:,:,:,[0, 2]] = x_coords\n",
    "                y_coords = boxes_tensor[:,:,:,[1, 3]]\n",
    "                y_coords[y_coords >= self.img_height] = self.img_height - 1\n",
    "                y_coords[y_coords < 0] = 0\n",
    "                boxes_tensor[:,:,:,[1, 3]] = y_coords\n",
    "\n",
    "            # If `normalize_coords` is enabled, normalize the coordinates to be within [0,1]\n",
    "            if self.normalize_coords:\n",
    "                boxes_tensor[:, :, :, [0, 2]] /= self.img_width\n",
    "                boxes_tensor[:, :, :, [1, 3]] /= self.img_height\n",
    "\n",
    "            # TODO: Implement box limiting directly for `(cx, cy, w, h)` so that we don't have to unnecessarily convert back and forth.\n",
    "            if self.coords == 'centroids':\n",
    "                # Convert `(xmin, ymin, xmax, ymax)` back to `(cx, cy, w, h)`.\n",
    "                boxes_tensor = convert_coordinates(boxes_tensor, start_index=0, conversion='corners2centroids', border_pixels='half')\n",
    "            elif self.coords == 'minmax':\n",
    "                # Convert `(xmin, ymin, xmax, ymax)` to `(xmin, xmax, ymin, ymax).\n",
    "                boxes_tensor = convert_coordinates(boxes_tensor, start_index=0, conversion='corners2minmax', border_pixels='half')\n",
    "\n",
    "            # Create a tensor to contain the variances and append it to `boxes_tensor`. This tensor has the same shape\n",
    "            # as `boxes_tensor` and simply contains the same 4 variance values for every position in the last axis.\n",
    "            variances_tensor = np.zeros_like(boxes_tensor) # Has shape `(feature_map_height, feature_map_width, n_boxes, 4)`\n",
    "            variances_tensor += self.variances # Long live broadcasting \n",
    "\n",
    "            # Now `boxes_tensor` becomes a tensor of shape `(feature_map_height, feature_map_width, n_boxes, 8)`\n",
    "            boxes_tensor = np.concatenate((boxes_tensor, variances_tensor), axis=-1)\n",
    "\n",
    "            # Now prepend one dimension to `boxes_tensor` to account for the batch size and tile it along\n",
    "            # The result will be a 5D tensor of shape `(batch_size, feature_map_height, feature_map_width, n_boxes, 8)`\n",
    "            boxes_tensor = np.expand_dims(boxes_tensor, axis=0)\n",
    "\n",
    "\n",
    "            boxes_tensor=tf.constant(value=boxes_tensor,dtype=tf.float32)\n",
    "            boxes_tensor=tf.reshape(boxes_tensor,[-1,feature_map_height,feature_map_width,n_boxes,8])\n",
    "\n",
    "            return boxes_tensor\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
