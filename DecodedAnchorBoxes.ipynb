{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decode the raw SSD predictions output.\n",
    "\n",
    "\n",
    "#INPUT shape:  3D Tensor (batch_size,n_boxes,n_classes +12)\n",
    "\n",
    "#--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+\n",
    "\n",
    "# We get the input from the model_fn.py file when calculate predictions\n",
    "\n",
    "# < predictions=tf.concat(values=[mbox_conf_softmax, mbox_loc, mbox_priorbox],axis=0)>\n",
    "\n",
    "# mbox_conf_sotfmax -predicted  probabilities of the classes presence in the bboxes | len(mbox_conf_sotfmax)=20 (20 classes)\n",
    "\n",
    "# mbox_loc - predicted shifts of the bboxes | len (mbox_loc)=4 (cx,cy,w,h)\n",
    "\n",
    "# mbox_priorbox - default coordinates and sizes of default priors + variance | len(mbox_priorbox)=8 (cx,cy,w,h,var1,var1,var2,var2)\n",
    "\n",
    "#--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+\n",
    "\n",
    "\n",
    "#OUTPUT shape : 3D Tensor (batch_size,top_k,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecodeDetections(Layer):\n",
    "    \n",
    "    def __init__(self,\n",
    "                confidence_thresh=0.01,\n",
    "                iou_threshold=0.45,\n",
    "                top_k=200,\n",
    "                nms_max_output_size=400,\n",
    "                coords='centroids',\n",
    "                normalize_coords=True,\n",
    "                img_height=None,\n",
    "                img_width=None,\n",
    "                **kwargs):\n",
    "        \n",
    "        # We need these members for the config.\n",
    "        self.confidence_thresh = confidence_thresh\n",
    "        self.iou_threshold = iou_threshold\n",
    "        \n",
    "        self.top_k = top_k\n",
    "        self.normalize_coords = normalize_coords\n",
    "        self.img_height = img_height\n",
    "        \n",
    "        self.img_width = img_width\n",
    "        self.coords = coords\n",
    "        \n",
    "        self.nms_max_output_size = nms_max_output_size\n",
    "\n",
    "        # We need these members for TensorFlow.\n",
    "        self.tf_confidence_thresh = tf.constant(self.confidence_thresh, name='confidence_thresh')\n",
    "        self.tf_iou_threshold = tf.constant(self.iou_threshold, name='iou_threshold')\n",
    "        \n",
    "        self.tf_top_k = tf.constant(self.top_k, name='top_k')\n",
    "        self.tf_normalize_coords = tf.constant(self.normalize_coords, name='normalize_coords')\n",
    "        \n",
    "        self.tf_img_height = tf.constant(self.img_height, dtype=tf.float32, name='img_height')\n",
    "        self.tf_img_width = tf.constant(self.img_width, dtype=tf.float32, name='img_width')\n",
    "        \n",
    "        self.tf_nms_max_output_size = tf.constant(self.nms_max_output_size, name='nms_max_output_size')\n",
    "        \n",
    "        \n",
    "    def call(self,y_pred,mask=None):\n",
    "        \n",
    "        #3D tensor of shape (batch_size, top_k, 6). The second axis is zero-padded\n",
    "        #to always yield top_k predictions per batch item. The last axis contains\n",
    "        #the coordinates for each predicted box in the format\n",
    "        #[class_id, confidence, xmin, ymin, xmax, ymax]\n",
    "        \n",
    "        \n",
    "        #--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+\n",
    "        # 1. Convert the box coordinates from predicted anchor box offsets to predicted\n",
    "        # absolute coordinates\n",
    "        #--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+\n",
    "        \n",
    "        # Convert anchor box offsets to image offsets\n",
    "        \n",
    "        # y_pred = [class_conf1 ....class_conf2 ,cx_shift,cy_shift,w_shift,h_shift,cx,cy,w,h,var1,var1,var2,var2]\n",
    "        \n",
    "        cx = y_pred[...,-12]*y_pred[...,-4]*y_pred[...,-6]+y_pred[...,-8] # cx = cx_pred * cx_variance * w_anchor + cx_anchor\n",
    "        cy = y_pred[...,-11]*y_pred[...,-3]*y_pred[...,-5]+y_pred[...,-7] # cy = cy_pred * cy_variance * h_anchor + cy_anchor\n",
    "        w = tf.exp(y_pred[...,-10] * y_pred[...,-2]) * y_pred[...,-6] # w = exp(w_pred * variance_w) * w_anchor\n",
    "        h = tf.exp(y_pred[...,-9] * y_pred[...,-1]) * y_pred[...,-5] # h = exp(h_pred * variance_h) * h_anchor\n",
    "        \n",
    "        # we have calculated the finish coordinates of bboxes in relative system coords\n",
    "        \n",
    "        #now we have to convert relative coords to corners coords (xmin,ymin,xmax,ymax)\n",
    "        # Convert centroids to corners.\n",
    "        \n",
    "        xmin = cx - 0.5 * w\n",
    "        ymin = cy - 0.5 * h\n",
    "        xmax = cx + 0.5 * w\n",
    "        ymax = cy + 0.5 * h\n",
    "        \n",
    "        #We can use 2 types of coords : relative and absolute.And in each type format we have to add 1 extra dim for batch_size\n",
    "        \n",
    "        def normalized_coords():\n",
    "            #Add dim for batch_size\n",
    "            xmin1 = tf.expand_dims(xmin * self.tf_img_width, axis=-1)\n",
    "            ymin1 = tf.expand_dims(ymin * self.tf_img_height, axis=-1)\n",
    "            xmax1 = tf.expand_dims(xmax * self.tf_img_width, axis=-1)\n",
    "            ymax1 = tf.expand_dims(ymax * self.tf_img_height, axis=-1)\n",
    "            return xmin1, ymin1, xmax1, ymax1\n",
    "        \n",
    "        def non_normalized_coords():\n",
    "            #Add dim for batch_size\n",
    "            return tf.expand_dims(xmin, axis=-1),tf.expand_dims(ymin, axis=-1) tf.expand_dims(xmax, axis=-1),tf.expand_dims(ymax, axis=-1)\n",
    "        \n",
    "        \n",
    "        #if self.tf_normalize_coords=True , use normalized_coords , else non_normalized_coords\n",
    "        xmin, ymin, xmax, ymax = tf.cond(self.tf_normalize_coords, normalized_coords(), non_normalized_coords())\n",
    "        \n",
    "        # Concatenate the one-hot class confidences and the converted box coordinates to form the decoded predictions tensor\n",
    "        \n",
    "        y_pred = tf.concat(values=[y_pred[...,:-12], xmin, ymin, xmax, ymax], axis=-1)\n",
    "        \n",
    "        #now we have 3D Tensor shape (batch_size,n_boxes,16) \n",
    "        #the last dim (16) consists of 20 classes one-hot confidence + 4 coords (xmin,ymin,xmax,ymax)\n",
    "        \n",
    "        \n",
    "        \n",
    "        #--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+\n",
    "        # 2. Perform confidence thresholding, per-class non-maximum suppression, and\n",
    "        #top-k filtering.\n",
    "        #--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+\n",
    "        \n",
    "        batch_size=tf.shape(y_pred)[0] # Output dtype: tf.int32\n",
    "        n_boxes=tf.shape(y_pred)[1]\n",
    "        n_classes=tf.shape(y_pred)[2]-4\n",
    "        class_indices=tf.range(1,n_classes)\n",
    "        \n",
    "        # Create a function that filters the predictions for the given batch item. Specifically, it performs:\n",
    "        # - confidence thresholding\n",
    "        # - non-maximum suppression (NMS)\n",
    "        # - top-k filtering\n",
    "        \n",
    "        def filter_predictions(batch_item): #batch_item i suppose it is y_pred!!!!!\n",
    "                \n",
    "            # Create a function that filters the predictions for one single class.\n",
    "            def filter_single_class(index)\n",
    "                # From a tensor of shape (n_boxes, n_classes + 4 coordinates) extract\n",
    "                # a tensor of shape (n_boxes, 1 + 4 coordinates) that contains the\n",
    "                # confidnece values for just one class, determined by index\n",
    "                \n",
    "                confidences = tf.expand_dims(batch_item[:,:,index], axis=-1) #shape (batch_size,n_boxes,1)\n",
    "                \n",
    "                class_id=tf.fill(dims=tf.shape(confidences),value=tf.float(index)) #shape (batch_size,n_boxes,1)\n",
    "                \n",
    "                box_coordinates = batch_item[...,-4:] #shape (batch_size,n_boxes,4)\n",
    "                \n",
    "                single_class = tf.concat([class_id, confidences, box_coordinates], axis=-1) #shape (batch_size,n_boxes,6)\n",
    "                \n",
    "                # Apply confidence thresholding with respect to the class defined by index\n",
    "                \n",
    "                threshold_met=single_class[:,1] > self.tf_confidense_thresh\n",
    "                \n",
    "                single_class=tf.boolean_mask(tensor=single_class,\n",
    "                                             mask=threshold_met)\n",
    "                \n",
    "                # If any boxes made the threshold, perform NMS\n",
    "                \n",
    "                def perform_nms():\n",
    "                    scores=single_class[:,:,1]\n",
    "                    \n",
    "                    #tf.image.non_max_suppression() needs the box coordinates in the format (ymin, xmin, ymax, xmax)\n",
    "                    \n",
    "                    xmin = tf.expand_dims(single_class[...,-4], axis=-1)\n",
    "                    ymin = tf.expand_dims(single_class[...,-3], axis=-1)\n",
    "                    xmax = tf.expand_dims(single_class[...,-2], axis=-1)\n",
    "                    ymax = tf.expand_dims(single_class[...,-1], axis=-1)\n",
    "                    boxes = tf.concat(values=[ymin, xmin, ymax, xmax], axis=-1)\n",
    "                    \n",
    "                    #apply tf function to calculate non maximum supression\n",
    "                    \n",
    "                    maxima_indices = tf.image.non_max_suppression(boxes=boxes,\n",
    "                                              scores=scores,\n",
    "                                              max_output_size=self.tf_nms_max_output_size,\n",
    "                                              iou_threshold=self.iou_threshold,\n",
    "                                              name='non_maximum_suppresion')\n",
    "                    \n",
    "                    #collect boxes after nms\n",
    "                    maxima = tf.gather(params=single_class,\n",
    "                                       ndices=maxima_indices,\n",
    "                                       axis=0)\n",
    "                    \n",
    "                    \n",
    "                    return maxima\n",
    "                \n",
    "                def no_confident_predictions():\n",
    "                    return tf.constant(value=0.0, shape=(1,6)) #WHY (1,6) not (1,6,1)\n",
    "                    \n",
    "                single_class_nms = tf.cond(tf.equal(tf.size(single_class), 0), no_confident_predictions, perform_nms)\n",
    "                    \n",
    "                # Make sure single_class is exactly self.nms_max_output_size elements long\n",
    "                    \n",
    "                padded_single_class = tf.pad(tensor=single_class_nms,\n",
    "                                                 paddings=[[0, self.tf_nms_max_output_size - tf.shape(single_class_nms)[0]], [0, 0]],\n",
    "                                                 mode='CONSTANT',\n",
    "                                                 constant_values=0.0)\n",
    "\n",
    "                return padded_single_class\n",
    "                \n",
    "            # Iterate filter_single_class() over all class indices.\n",
    "            filtered_single_classes = tf.map_fn(fn=lambda i: filter_single_class(i),\n",
    "                                                elems=tf.range(1,n_classes),\n",
    "                                                dtype=tf.float32,\n",
    "                                                parallel_iterations=128,\n",
    "                                                back_prop=False,\n",
    "                                                swap_memory=False,\n",
    "                                                infer_shape=True,\n",
    "                                                name='loop_over_classes')\n",
    "                    \n",
    "            # Concatenate the filtered results for all individual classes to one tensor.\n",
    "            filtered_predictions = tf.reshape(tensor=filtered_single_classes, shape=(-1,6))\n",
    "                    \n",
    "            \n",
    "            # Perform top-k filtering for this batch item or pad it in case there are\n",
    "            # fewer than `self.top_k` boxes left at this point. Either way, produce a\n",
    "            # tensor of length `self.top_k`. By the time we return the final results tensor\n",
    "            # for the whole batch, all batch items must have the same number of predicted\n",
    "            # boxes so that the tensor dimensions are homogenous. If fewer than `self.top_k`\n",
    "            # predictions are left after the filtering process above, we pad the missing\n",
    "            # predictions with zeros as dummy entries.\n",
    "            def top_k():\n",
    "                return tf.gather(params=filtered_predictions,\n",
    "                                 indices=tf.nn.top_k(filtered_predictions[:, 1], k=self.tf_top_k, sorted=True).indices,\n",
    "                                 axis=0)\n",
    "            def pad_and_top_k():\n",
    "                padded_predictions = tf.pad(tensor=filtered_predictions,\n",
    "                                            paddings=[[0, self.tf_top_k - tf.shape(filtered_predictions)[0]], [0, 0]],\n",
    "                                            mode='CONSTANT',\n",
    "                                            constant_values=0.0)\n",
    "                return tf.gather(params=padded_predictions,\n",
    "                                 indices=tf.nn.top_k(padded_predictions[:, 1], k=self.tf_top_k, sorted=True).indices,\n",
    "                                 axis=0)\n",
    "\n",
    "            top_k_boxes = tf.cond(tf.greater_equal(tf.shape(filtered_predictions)[0], self.tf_top_k), top_k, pad_and_top_k)\n",
    "\n",
    "            return top_k_boxes\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test shapes of Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_img_height=300\n",
    "tf_img_width=300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=np.random.rand(1,100,32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100, 32)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=tf.reshape(data,[-1,100,32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "cx = y_pred[...,-12]*y_pred[...,-4]*y_pred[...,-6]+y_pred[...,-8] # cx = cx_pred * cx_variance * w_anchor + cx_anchor\n",
    "cy = y_pred[...,-11]*y_pred[...,-3]*y_pred[...,-5]+y_pred[...,-7] # cy = cy_pred * cy_variance * h_anchor + cy_anchor\n",
    "w = tf.exp(y_pred[...,-10] * y_pred[...,-2]) * y_pred[...,-6] # w = exp(w_pred * variance_w) * w_anchor\n",
    "h = tf.exp(y_pred[...,-9] * y_pred[...,-1]) * y_pred[...,-5] # h = exp(h_pred * variance_h) * h_anchor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([Dimension(1), Dimension(100)]),\n",
       " TensorShape([Dimension(1), Dimension(100)]),\n",
       " TensorShape([Dimension(1), Dimension(100)]),\n",
       " TensorShape([Dimension(1), Dimension(100)]))"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cx.get_shape(),cy.get_shape(),w.get_shape(),h.get_shape()\n",
    "\n",
    "# (1,100) 100 - n_boxes\n",
    "# (1,100)\n",
    "# (1,100)\n",
    "# (1,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "xmin = cx - 0.5 * w\n",
    "ymin = cy - 0.5 * h\n",
    "xmax = cx + 0.5 * w\n",
    "ymax = cy + 0.5 * h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<bound method Tensor.get_shape of <tf.Tensor 'sub_4:0' shape=(1, 100) dtype=float64>>,\n",
       " <bound method Tensor.get_shape of <tf.Tensor 'sub_5:0' shape=(1, 100) dtype=float64>>,\n",
       " <bound method Tensor.get_shape of <tf.Tensor 'add_12:0' shape=(1, 100) dtype=float64>>,\n",
       " <bound method Tensor.get_shape of <tf.Tensor 'add_13:0' shape=(1, 100) dtype=float64>>)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xmin.get_shape,ymin.get_shape,xmax.get_shape,ymax.get_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (1,100) 100 - n_boxes\n",
    "# (1,100)\n",
    "# (1,100)\n",
    "# (1,100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def normalized_coords():\n",
    "    #Add dim for batch_size\n",
    "    xmin1 = tf.expand_dims(xmin * self.tf_img_width, axis=-1)\n",
    "    ymin1 = tf.expand_dims(ymin * self.tf_img_height, axis=-1)\n",
    "    xmax1 = tf.expand_dims(xmax * self.tf_img_width, axis=-1)\n",
    "    ymax1 = tf.expand_dims(ymax * self.tf_img_height, axis=-1)\n",
    "    return xmin1, ymin1, xmax1, ymax1\n",
    "\n",
    "def non_normalized_coords():\n",
    "    #Add dim for batch_size\n",
    "    return tf.expand_dims(xmin, axis=-1),tf.expand_dims(ymin, axis=-1) tf.expand_dims(xmax, axis=-1),tf.expand_dims(ymax, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalized_coords():\n",
    "    #Add dim for batch_size\n",
    "    xmin1 = tf.expand_dims(xmin * tf_img_width, axis=-1)\n",
    "    ymin1 = tf.expand_dims(ymin * tf_img_height, axis=-1)\n",
    "    xmax1 = tf.expand_dims(xmax * tf_img_width, axis=-1)\n",
    "    ymax1 = tf.expand_dims(ymax * tf_img_height, axis=-1)\n",
    "    return xmin1, ymin1, xmax1, ymax1\n",
    "\n",
    "def non_normalized_coords():\n",
    "    #Add dim for batch_size\n",
    "    return tf.expand_dims(xmin, axis=-1),tf.expand_dims(ymin, axis=-1),tf.expand_dims(xmax, axis=-1),tf.expand_dims(ymax, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "xmin1, ymin1, xmax1, ymax1=normalized_coords()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([Dimension(1), Dimension(100), Dimension(1)]),\n",
       " TensorShape([Dimension(1), Dimension(100), Dimension(1)]),\n",
       " TensorShape([Dimension(1), Dimension(100), Dimension(1)]),\n",
       " TensorShape([Dimension(1), Dimension(100), Dimension(1)]))"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xmin1.get_shape(), ymin1.get_shape(), xmax1.get_shape(), ymax1.get_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (1,100,1)\n",
    "# (1,100,1)\n",
    "# (1,100,1)\n",
    "# (1,100,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "xmin, ymin, xmax, ymax = tf.cond(tf.constant(True, name='normalize_coords'), normalized_coords, non_normalized_coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (1,100,1)\n",
    "# (1,100,1)\n",
    "# (1,100,1)\n",
    "# (1,100,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = tf.concat(values=[y_pred[...,:-12], xmin, ymin, xmax, ymax], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'concat_4:0' shape=(1, 100, 24) dtype=float64>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (1,100,24) 100 boxes | 24 = 20 classes + 4 coords "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_item=y_pred\n",
    "confidences = tf.expand_dims(batch_item[:,:,0], axis=-1) \n",
    "class_id=tf.fill(dims=tf.shape(confidences),value=tf.cast(0,tf.float64)) #shape (batch_size,n_boxes,1)\n",
    "box_coordinates = batch_item[...,-4:] #shape (batch_size,n_boxes,4)\n",
    "\n",
    "single_class = tf.concat([class_id, confidences, box_coordinates], axis=-1) #shape (batch_size,n_boxes,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([Dimension(1), Dimension(100), Dimension(1)]),\n",
       " TensorShape([Dimension(1), Dimension(100), Dimension(1)]),\n",
       " TensorShape([Dimension(1), Dimension(100), Dimension(4)]),\n",
       " TensorShape([Dimension(1), Dimension(100), Dimension(6)]))"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confidences.get_shape(),class_id.get_shape(),box_coordinates.get_shape(),single_class.get_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (1,100,1)\n",
    "# (1,100,1)\n",
    "# (1,100,4)\n",
    "# (1,100,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_met=single_class[:,1] > 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(1), Dimension(6)])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold_met.get_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shapes (1, 100) and (1, 6) are incompatible",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-125-a0cdfbadb18f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msingle_class\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mboolean_mask\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msingle_class\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mthreshold_met\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36mboolean_mask\u001b[1;34m(tensor, mask, name, axis)\u001b[0m\n\u001b[0;32m   1178\u001b[0m           \" are None.  E.g. shape=[None] is ok, but shape=None is not.\")\n\u001b[0;32m   1179\u001b[0m     \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1180\u001b[1;33m     \u001b[0mshape_tensor\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0maxis\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mndims_mask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massert_is_compatible_with\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1181\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1182\u001b[0m     \u001b[0mleading_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0maxis\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mndims_mask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py\u001b[0m in \u001b[0;36massert_is_compatible_with\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    845\u001b[0m     \"\"\"\n\u001b[0;32m    846\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 847\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Shapes %s and %s are incompatible\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    848\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    849\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mmost_specific_compatible_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Shapes (1, 100) and (1, 6) are incompatible"
     ]
    }
   ],
   "source": [
    "single_class=tf.boolean_mask(tensor=single_class,mask=threshold_met)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(1), Dimension(6)])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_class[:,1].get_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
