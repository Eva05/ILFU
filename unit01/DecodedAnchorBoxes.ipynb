{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width=300\n",
    "img_height=300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decode the raw SSD predictions output.\n",
    "\n",
    "\n",
    "#INPUT shape:  3D Tensor (batch_size,n_boxes,n_classes +12)\n",
    "\n",
    "#--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+\n",
    "\n",
    "# We get the input from the model_fn.py file when calculate predictions\n",
    "\n",
    "# < predictions=tf.concat(values=[mbox_conf_softmax, mbox_loc, mbox_priorbox],axis=0)>\n",
    "\n",
    "# mbox_conf_sotfmax -predicted  probabilities of the classes presence in the bboxes | len(mbox_conf_sotfmax)=20 (20 classes)\n",
    "\n",
    "# mbox_loc - predicted shifts of the bboxes | len (mbox_loc)=4 (cx,cy,w,h)\n",
    "\n",
    "# mbox_priorbox - default coordinates and sizes of default priors + variance | len(mbox_priorbox)=8 (cx,cy,w,h,var1,var1,var2,var2)\n",
    "\n",
    "#--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+\n",
    "\n",
    "\n",
    "#OUTPUT shape : 3D Tensor (batch_size,top_k,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class DecodeDetections(Layer):\n",
    "    \n",
    "#     def __init__(self,\n",
    "#                 confidence_thresh=0.01,\n",
    "#                 iou_threshold=0.45,\n",
    "#                 top_k=200,\n",
    "#                 nms_max_output_size=400,\n",
    "#                 coords='centroids',\n",
    "#                 normalize_coords=True,\n",
    "#                 img_height=None,\n",
    "#                 img_width=None,\n",
    "#                 **kwargs):\n",
    "        \n",
    "#         # We need these members for the config.\n",
    "#         self.confidence_thresh = confidence_thresh\n",
    "#         self.iou_threshold = iou_threshold\n",
    "        \n",
    "#         self.top_k = top_k\n",
    "#         self.normalize_coords = normalize_coords\n",
    "#         self.img_height = img_height\n",
    "        \n",
    "#         self.img_width = img_width\n",
    "#         self.coords = coords\n",
    "        \n",
    "#         self.nms_max_output_size = nms_max_output_size\n",
    "\n",
    "#         # We need these members for TensorFlow.\n",
    "#         self.tf_confidence_thresh = tf.constant(self.confidence_thresh, name='confidence_thresh')\n",
    "#         self.tf_iou_threshold = tf.constant(self.iou_threshold, name='iou_threshold')\n",
    "        \n",
    "#         self.tf_top_k = tf.constant(self.top_k, name='top_k')\n",
    "#         self.tf_normalize_coords = tf.constant(self.normalize_coords, name='normalize_coords')\n",
    "        \n",
    "#         self.tf_img_height = tf.constant(self.img_height, dtype=tf.float32, name='img_height')\n",
    "#         self.tf_img_width = tf.constant(self.img_width, dtype=tf.float32, name='img_width')\n",
    "        \n",
    "#         self.tf_nms_max_output_size = tf.constant(self.nms_max_output_size, name='nms_max_output_size')\n",
    "        \n",
    "        \n",
    "#     def call(self,y_pred,mask=None):\n",
    "        \n",
    "#         #3D tensor of shape (batch_size, top_k, 6). The second axis is zero-padded\n",
    "#         #to always yield top_k predictions per batch item. The last axis contains\n",
    "#         #the coordinates for each predicted box in the format\n",
    "#         #[class_id, confidence, xmin, ymin, xmax, ymax]\n",
    "        \n",
    "        \n",
    "#         #--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+\n",
    "#         # 1. Convert the box coordinates from predicted anchor box offsets to predicted\n",
    "#         # absolute coordinates\n",
    "#         #--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+\n",
    "        \n",
    "#         # Convert anchor box offsets to image offsets\n",
    "        \n",
    "#         # y_pred = [class_conf1 ....class_conf2 ,cx_shift,cy_shift,w_shift,h_shift,cx,cy,w,h,var1,var1,var2,var2]\n",
    "        \n",
    "#         cx = y_pred[...,-12]*y_pred[...,-4]*y_pred[...,-6]+y_pred[...,-8] # cx = cx_pred * cx_variance * w_anchor + cx_anchor\n",
    "#         cy = y_pred[...,-11]*y_pred[...,-3]*y_pred[...,-5]+y_pred[...,-7] # cy = cy_pred * cy_variance * h_anchor + cy_anchor\n",
    "#         w = tf.exp(y_pred[...,-10] * y_pred[...,-2]) * y_pred[...,-6] # w = exp(w_pred * variance_w) * w_anchor\n",
    "#         h = tf.exp(y_pred[...,-9] * y_pred[...,-1]) * y_pred[...,-5] # h = exp(h_pred * variance_h) * h_anchor\n",
    "        \n",
    "#         # we have calculated the finish coordinates of bboxes in relative system coords\n",
    "        \n",
    "#         #now we have to convert relative coords to corners coords (xmin,ymin,xmax,ymax)\n",
    "#         # Convert centroids to corners.\n",
    "        \n",
    "#         xmin = cx - 0.5 * w\n",
    "#         ymin = cy - 0.5 * h\n",
    "#         xmax = cx + 0.5 * w\n",
    "#         ymax = cy + 0.5 * h\n",
    "        \n",
    "#         #We can use 2 types of coords : relative and absolute.And in each type format we have to add 1 extra dim for batch_size\n",
    "        \n",
    "#         def normalized_coords():\n",
    "#             #Add dim for batch_size\n",
    "#             xmin1 = tf.expand_dims(xmin * self.tf_img_width, axis=-1)\n",
    "#             ymin1 = tf.expand_dims(ymin * self.tf_img_height, axis=-1)\n",
    "#             xmax1 = tf.expand_dims(xmax * self.tf_img_width, axis=-1)\n",
    "#             ymax1 = tf.expand_dims(ymax * self.tf_img_height, axis=-1)\n",
    "#             return xmin1, ymin1, xmax1, ymax1\n",
    "        \n",
    "#         def non_normalized_coords():\n",
    "#             #Add dim for batch_size\n",
    "#             return tf.expand_dims(xmin, axis=-1),tf.expand_dims(ymin, axis=-1) tf.expand_dims(xmax, axis=-1),tf.expand_dims(ymax, axis=-1)\n",
    "        \n",
    "        \n",
    "#         #if self.tf_normalize_coords=True , use normalized_coords , else non_normalized_coords\n",
    "#         xmin, ymin, xmax, ymax = tf.cond(self.tf_normalize_coords, normalized_coords(), non_normalized_coords())\n",
    "        \n",
    "#         # Concatenate the one-hot class confidences and the converted box coordinates to form the decoded predictions tensor\n",
    "        \n",
    "#         y_pred = tf.concat(values=[y_pred[...,:-12], xmin, ymin, xmax, ymax], axis=-1)\n",
    "        \n",
    "#         #now we have 3D Tensor shape (batch_size,n_boxes,16) \n",
    "#         #the last dim (16) consists of 20 classes one-hot confidence + 4 coords (xmin,ymin,xmax,ymax)\n",
    "        \n",
    "        \n",
    "        \n",
    "#         #--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+\n",
    "#         # 2. Perform confidence thresholding, per-class non-maximum suppression, and\n",
    "#         #top-k filtering.\n",
    "#         #--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+\n",
    "        \n",
    "#         batch_size=tf.shape(y_pred)[0] # Output dtype: tf.int32\n",
    "#         n_boxes=tf.shape(y_pred)[1]\n",
    "#         n_classes=tf.shape(y_pred)[2]-4\n",
    "#         class_indices=tf.range(1,n_classes)\n",
    "        \n",
    "#         # Create a function that filters the predictions for the given batch item. Specifically, it performs:\n",
    "#         # - confidence thresholding\n",
    "#         # - non-maximum suppression (NMS)\n",
    "#         # - top-k filtering\n",
    "        \n",
    "#         def filter_predictions(batch_item): #batch_item i suppose it is y_pred!!!!!\n",
    "                \n",
    "#             # Create a function that filters the predictions for one single class.\n",
    "#             def filter_single_class(index)\n",
    "#                 # From a tensor of shape (n_boxes, n_classes + 4 coordinates) extract\n",
    "#                 # a tensor of shape (n_boxes, 1 + 4 coordinates) that contains the\n",
    "#                 # confidnece values for just one class, determined by index\n",
    "                \n",
    "#                 confidences = tf.expand_dims(batch_item[:,:,index], axis=-1) #shape (batch_size,n_boxes,1)\n",
    "                \n",
    "#                 class_id=tf.fill(dims=tf.shape(confidences),value=tf.float(index)) #shape (batch_size,n_boxes,1)\n",
    "                \n",
    "#                 box_coordinates = batch_item[...,-4:] #shape (batch_size,n_boxes,4)\n",
    "                \n",
    "#                 single_class = tf.concat([class_id, confidences, box_coordinates], axis=-1) #shape (batch_size,n_boxes,6)\n",
    "                \n",
    "#                 # Apply confidence thresholding with respect to the class defined by index\n",
    "                \n",
    "#                 threshold_met=single_class[:,1] > self.tf_confidense_thresh\n",
    "                \n",
    "#                 single_class=tf.boolean_mask(tensor=single_class,\n",
    "#                                              mask=threshold_met)\n",
    "                \n",
    "#                 # If any boxes made the threshold, perform NMS\n",
    "                \n",
    "#                 def perform_nms():\n",
    "#                     scores=single_class[:,:,1]\n",
    "                    \n",
    "#                     #tf.image.non_max_suppression() needs the box coordinates in the format (ymin, xmin, ymax, xmax)\n",
    "                    \n",
    "#                     xmin = tf.expand_dims(single_class[...,-4], axis=-1)\n",
    "#                     ymin = tf.expand_dims(single_class[...,-3], axis=-1)\n",
    "#                     xmax = tf.expand_dims(single_class[...,-2], axis=-1)\n",
    "#                     ymax = tf.expand_dims(single_class[...,-1], axis=-1)\n",
    "#                     boxes = tf.concat(values=[ymin, xmin, ymax, xmax], axis=-1)\n",
    "                    \n",
    "#                     #apply tf function to calculate non maximum supression\n",
    "                    \n",
    "#                     maxima_indices = tf.image.non_max_suppression(boxes=boxes,\n",
    "#                                               scores=scores,\n",
    "#                                               max_output_size=self.tf_nms_max_output_size,\n",
    "#                                               iou_threshold=self.iou_threshold,\n",
    "#                                               name='non_maximum_suppresion')\n",
    "                    \n",
    "#                     #collect boxes after nms\n",
    "#                     maxima = tf.gather(params=single_class,\n",
    "#                                        ndices=maxima_indices,\n",
    "#                                        axis=0)\n",
    "                    \n",
    "                    \n",
    "#                     return maxima\n",
    "                \n",
    "#                 def no_confident_predictions():\n",
    "#                     return tf.constant(value=0.0, shape=(1,6)) #WHY (1,6) not (1,6,1)\n",
    "                    \n",
    "#                 single_class_nms = tf.cond(tf.equal(tf.size(single_class), 0), no_confident_predictions, perform_nms)\n",
    "                    \n",
    "#                 # Make sure single_class is exactly self.nms_max_output_size elements long\n",
    "                    \n",
    "#                 padded_single_class = tf.pad(tensor=single_class_nms,\n",
    "#                                                  paddings=[[0, self.tf_nms_max_output_size - tf.shape(single_class_nms)[0]], [0, 0]],\n",
    "#                                                  mode='CONSTANT',\n",
    "#                                                  constant_values=0.0)\n",
    "\n",
    "#                 return padded_single_class\n",
    "                \n",
    "#             # Iterate filter_single_class() over all class indices.\n",
    "#             filtered_single_classes = tf.map_fn(fn=lambda i: filter_single_class(i),\n",
    "#                                                 elems=tf.range(1,n_classes),\n",
    "#                                                 dtype=tf.float32,\n",
    "#                                                 parallel_iterations=128,\n",
    "#                                                 back_prop=False,\n",
    "#                                                 swap_memory=False,\n",
    "#                                                 infer_shape=True,\n",
    "#                                                 name='loop_over_classes')\n",
    "                    \n",
    "#             # Concatenate the filtered results for all individual classes to one tensor.\n",
    "#             filtered_predictions = tf.reshape(tensor=filtered_single_classes, shape=(-1,6))\n",
    "                    \n",
    "            \n",
    "#             # Perform top-k filtering for this batch item or pad it in case there are\n",
    "#             # fewer than `self.top_k` boxes left at this point. Either way, produce a\n",
    "#             # tensor of length `self.top_k`. By the time we return the final results tensor\n",
    "#             # for the whole batch, all batch items must have the same number of predicted\n",
    "#             # boxes so that the tensor dimensions are homogenous. If fewer than `self.top_k`\n",
    "#             # predictions are left after the filtering process above, we pad the missing\n",
    "#             # predictions with zeros as dummy entries.\n",
    "#             def top_k():\n",
    "#                 return tf.gather(params=filtered_predictions,\n",
    "#                                  indices=tf.nn.top_k(filtered_predictions[:, 1], k=self.tf_top_k, sorted=True).indices,\n",
    "#                                  axis=0)\n",
    "#             def pad_and_top_k():\n",
    "#                 padded_predictions = tf.pad(tensor=filtered_predictions,\n",
    "#                                             paddings=[[0, self.tf_top_k - tf.shape(filtered_predictions)[0]], [0, 0]],\n",
    "#                                             mode='CONSTANT',\n",
    "#                                             constant_values=0.0)\n",
    "#                 return tf.gather(params=padded_predictions,\n",
    "#                                  indices=tf.nn.top_k(padded_predictions[:, 1], k=self.tf_top_k, sorted=True).indices,\n",
    "#                                  axis=0)\n",
    "\n",
    "#             top_k_boxes = tf.cond(tf.greater_equal(tf.shape(filtered_predictions)[0], self.tf_top_k), top_k, pad_and_top_k)\n",
    "\n",
    "#             return top_k_boxes\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test shapes of Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecodeDetections:\n",
    "\n",
    "    '''TensorFlow layer which we have created in model_fn.py file ,\n",
    "\n",
    "    while training a model.\n",
    "\n",
    "    Layer is a 3D Tensor with shape (batch_size,n_boxes,n_classes +12)\n",
    "\n",
    "    12 last magnitudes consists of 4 predicted shifts of anchors (cx,cy,w,h)\n",
    "\n",
    "    and of 8 default anchor boxes  coordinates (cx,cy,w,h,var1,var1,var2,var2)\n",
    "\n",
    "    Layer= confidences + locations + anchors\n",
    "\n",
    "    INPUT_SHAPE : (batch_size,n_boxes,n_classes+12)\n",
    "\n",
    "    OUTPUT SHAPE : (batch_size,top_k,6)\n",
    "\n",
    "    '''\n",
    "\n",
    "    def __init__(self,\n",
    "        confidence_thresh=0.01,\n",
    "        iou_threshold=0.45,\n",
    "        top_k=200,\n",
    "        nms_max_output_size=400,\n",
    "        coords='centroids',\n",
    "        normalize_coords=True,\n",
    "        img_height=None,\n",
    "        img_width=None,\n",
    "        **kwargs):\n",
    "\n",
    "        '''\n",
    "        All default argument values follow the Caffe implementation.\n",
    "        Arguments:\n",
    "\n",
    "        confidence_thresh (float, optional): A float in [0,1), the minimum classification confidence in a specific\n",
    "        positive class in order to be considered for the non-maximum suppression stage for the respective class.\n",
    "        A lower value will result in a larger part of the selection process being done by the non-maximum suppression\n",
    "        stage, while a larger value will result in a larger part of the selection process happening in the confidence\n",
    "        thresholding stage.\n",
    "\n",
    "        iou_threshold (float, optional): A float in [0,1]. All boxes with a Jaccard similarity of greater than iou_threshold\n",
    "        with a locally maximal box will be removed from the set of predictions for a given class, where maximal refers\n",
    "        to the box score.\n",
    "\n",
    "        top_k (int, optional): The number of highest scoring predictions to be kept for each batch item after the\n",
    "        non-maximum suppression stage.\n",
    "\n",
    "        nms_max_output_size (int, optional): The maximum number of predictions that will be left after performing non-maximum\n",
    "        suppression.\n",
    "\n",
    "        coords (str, optional): The box coordinate format that the model outputs. Must be 'centroids'\n",
    "        i.e. the format (cx, cy, w, h) (box center coordinates, width, and height). Other coordinate formats are\n",
    "        currently not supported.\n",
    "\n",
    "        normalize_coords (bool, optional): Set to True if the model outputs relative coordinates (i.e. coordinates in [0,1])\n",
    "        and you wish to transform these relative coordinates back to absolute coordinates. If the model outputs\n",
    "        relative coordinates, but you do not want to convert them back to absolute coordinates, set this to False.\n",
    "        Do not set this to True if the model already outputs absolute coordinates, as that would result in incorrect\n",
    "        coordinates. Requires img_height and img_width if set to True.\n",
    "\n",
    "        img_height (int, optional): The height of the input images. Only needed if normalize_coords is True.\n",
    "\n",
    "        img_width (int, optional): The width of the input images. Only needed if normalize_coords is True.\n",
    "\n",
    "        '''\n",
    "\n",
    "\n",
    "        # We need these members for the config.\n",
    "        self.confidence_thresh = confidence_thresh\n",
    "        self.iou_threshold = iou_threshold\n",
    "        self.top_k = top_k\n",
    "        self.normalize_coords = normalize_coords\n",
    "        self.img_height = img_height\n",
    "        self.img_width = img_width\n",
    "        self.coords = coords\n",
    "        self.nms_max_output_size = nms_max_output_size\n",
    "\n",
    "\n",
    "        # We need these members for TensorFlow.\n",
    "        self.tf_confidence_thresh = tf.constant(self.confidence_thresh, name='confidence_thresh')\n",
    "        self.tf_iou_threshold = tf.constant(self.iou_threshold, name='iou_threshold')\n",
    "        self.tf_top_k = tf.constant(self.top_k, name='top_k')\n",
    "        self.tf_normalize_coords = tf.constant(self.normalize_coords, name='normalize_coords')\n",
    "        self.tf_img_height = tf.constant(self.img_height, dtype=tf.float32, name='img_height')\n",
    "        self.tf_img_width = tf.constant(self.img_width, dtype=tf.float32, name='img_width')\n",
    "        self.tf_nms_max_output_size = tf.constant(self.nms_max_output_size, name='nms_max_output_size')\n",
    "\n",
    "\n",
    "        super(DecodeDetections, self).__init__(**kwargs) #I DONT UNDERSTAND WHAT IT MEANS\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def call(self,y_pred,mask=None):\n",
    "\n",
    "        '''\n",
    "        Returns:\n",
    "        3D tensor of shape (batch_size, top_k, 6). The second axis is zero-padded\n",
    "        to always yield `top_k` predictions per batch item. The last axis contains\n",
    "        the coordinates for each predicted box in the format\n",
    "        [class_id, confidence, xmin, ymin, xmax, ymax].\n",
    "        '''\n",
    "\n",
    "        ###########################################################################\n",
    "        '''STAGE 1. Convert the box coordinates from predicted anchor \n",
    "        box offsets to predictedabsolute coordinates'''\n",
    "        ###########################################################################\n",
    "        \n",
    "        print('Начало конвертации координат')\n",
    "\n",
    "        #Convert anchor box offsets to image offsets.\n",
    "\n",
    "        # cx = cx_pred * cx_variance * w_anchor + cx_anchor\n",
    "        cx = y_pred[...,-12] * y_pred[...,-4] * y_pred[...,-6] + y_pred[...,-8]\n",
    "        # cy = cy_pred * cy_variance * h_anchor + cy_anchor\n",
    "        cy = y_pred[...,-11] * y_pred[...,-3] * y_pred[...,-5] + y_pred[...,-7]\n",
    "        # w = exp(w_pred * variance_w) * w_anchor\n",
    "        w = tf.exp(y_pred[...,-10] * y_pred[...,-2]) * y_pred[...,-6]\n",
    "        # h = exp(h_pred * variance_h) * h_anchor\n",
    "        h = tf.exp(y_pred[...,-9] * y_pred[...,-1]) * y_pred[...,-5]\n",
    "\n",
    "        #Convert 'centroids' to corners\n",
    "\n",
    "        xmin = cx - 0.5 * w\n",
    "        ymin = cy - 0.5 * h\n",
    "        xmax = cx + 0.5 * w\n",
    "        ymax = cy + 0.5 * h\n",
    "        \n",
    "        print('Конец конвертации')\n",
    "        \n",
    "        print('Объявление функций конвертации : относительные и абсолютные')\n",
    "\n",
    "        #We can choose of of two types of coords. Normalized ccords and Non Normalized\n",
    "\n",
    "        #Values of xmin,ymin,xmax,ymax lie between 0 and 1\n",
    "        def normalized_coords():\n",
    "            xmin1 = tf.expand_dims(xmin * self.tf_img_width, axis=-1)\n",
    "            ymin1 = tf.expand_dims(ymin * self.tf_img_height, axis=-1)\n",
    "            xmax1 = tf.expand_dims(xmax * self.tf_img_width, axis=-1)\n",
    "            ymax1 = tf.expand_dims(ymax * self.tf_img_height, axis=-1)\n",
    "            return xmin1, ymin1, xmax1, ymax1\n",
    "\n",
    "        #Values of xmin,xmax lie between 0 and img_width and ymin,ymax lie between 0 and img_height\n",
    "        def non_normalized_coords():\n",
    "            return tf.expand_dims(xmin, axis=-1), tf.expand_dims(ymin, axis=-1),tf.expand_dims(xmax, axis=-1), tf.expand_dims(ymax, axis=-1)\n",
    "            \n",
    "        print('Конец объявления функций конвертации : относительные и абсолютные')\n",
    "\n",
    "        print('Tf.cond')\n",
    "        \n",
    "        xmin, ymin, xmax, ymax = tf.cond(self.tf_normalize_coords, normalized_coords, non_normalized_coords)\n",
    "        \n",
    "        print('Конец Tf.cond')\n",
    "\n",
    "\n",
    "        '''Concatenate the one-hot class confidences and the converted box coordinates \n",
    "        to form the decoded predictions tensor'''\n",
    "        \n",
    "        print('соединяем 20 классов и 4 координаты')\n",
    "\n",
    "        #y_pred shape (batch_size,n_boxes,n_classes+4)\n",
    "        y_pred = tf.concat(values=[y_pred[...,:-12], xmin, ymin, xmax, ymax], axis=-1)\n",
    "\n",
    "\n",
    "        ###########################################################################\n",
    "        ''' STAGE 2. Perform :\n",
    "        -confidence thresholding\n",
    "        -per-class non-maximum suppression\n",
    "        -top-k filtering'''\n",
    "        ###########################################################################\n",
    "        \n",
    "        print('Задаем параметры')\n",
    "\n",
    "        batch_size=tf.shape(y_pred)[0] #Output dtype: tf.int32\n",
    "        n_boxes=tf.shape(y_pred)[1]\n",
    "        n_classes=tf.shape(y_pred)[2]-4\n",
    "        class_indices=tf.range(1,n_classes)\n",
    "\n",
    "        # Create a function that filters the predictions for the given batch item. Specifically, it performs:\n",
    "        # - confidence thresholding\n",
    "        # - non-maximum suppression (NMS)\n",
    "        # - top-k filtering\n",
    "\n",
    "\n",
    "        #Here,we iterate by batch_size.And shape becomes (n_boxes,classes+4)\n",
    "        def filter_predictions(batch_item):\n",
    "\n",
    "            # Create a function that filters the predictions for one single class.\n",
    "            def filter_single_class(index):\n",
    "\n",
    "                ''' \n",
    "                From a tensor of shape (n_boxes, n_classes + 4 coordinates) extract\n",
    "                a tensor of shape (n_boxes, 1 + 4 coordinates) that contains the\n",
    "                confidnece values for just one class, determined by index\n",
    "                '''\n",
    "\n",
    "\n",
    "                confidences=tf.expand_dims(batch_item[...,index],axis=-1)\n",
    "\n",
    "                class_id=tf.fill(dims=tf.shape(confidences),value=tf.to_float(index))\n",
    "\n",
    "                box_coordinates=batch_item[...,-4:]\n",
    "\n",
    "                single_class=tf.concat([class_id,confidences,box_coordinates],axis=-1)\n",
    "\n",
    "                #Apply confidence thresholding with respect to the class defined by index\n",
    "\n",
    "                threshold_met=single_class[:,1] > self.tf_confidence_thresh\n",
    "\n",
    "                single_class=tf.boolean_mask(tensor=single_class,\n",
    "                                             mask=threshold_met)\n",
    "\n",
    "                # single_class shape (n_boxes1 =< n_boxes, confidence + 4 coords)\n",
    "\n",
    "                #if any boxes made the threshold , perform NMS\n",
    "\n",
    "                def perform_nms():\n",
    "\n",
    "                    scores=single_class[...,1] #confidences\n",
    "\n",
    "                    # tf.image.non_max_suppression() needs the box coordinates in the format (ymin, xmin, ymax, xmax)\n",
    "\n",
    "                    xmin = tf.expand_dims(single_class[...,-4], axis=-1)\n",
    "                    ymin = tf.expand_dims(single_class[...,-3], axis=-1)\n",
    "                    xmax = tf.expand_dims(single_class[...,-2], axis=-1)\n",
    "                    ymax = tf.expand_dims(single_class[...,-1], axis=-1)\n",
    "\n",
    "                    boxes = tf.concat(values=[ymin, xmin, ymax, xmax], axis=-1)\n",
    "\n",
    "                    maxima_indicies = tf.image.non_max_suppression(boxes=boxes,\n",
    "                                                                  scores=scores,\n",
    "                                                                  max_output_size=self.tf_nms_max_output_size,\n",
    "                                                                  iou_threshold=self.iou_threshold,\n",
    "                                                                  name='non_maximum_suppresion')\n",
    "\n",
    "                    maxima=tf.gather(params=single_class,\n",
    "                                     indices=maxima_indicies,\n",
    "                                     axis=0)\n",
    "\n",
    "                    return maxima\n",
    "\n",
    "\n",
    "                def no_confident_predictions():\n",
    "\n",
    "                    return tf.constant(value=0.0,shape=(1,6))\n",
    "\n",
    "                #if there is no boxes in batch respect to unique class ,using no_confident_predictions\n",
    "                #else perform_nms\n",
    "\n",
    "                single_class_nms = tf.cond(tf.equal(tf.size(single_class), 0), no_confident_predictions, perform_nms)\n",
    "\n",
    "                # Make sure single_class`is exactly self.nms_max_output_size elements long.\n",
    "\n",
    "                padded_single_class = tf.pad(tensor=single_class_nms,\n",
    "                                             paddings=[[0, self.tf_nms_max_output_size - tf.shape(single_class_nms)[0]], [0, 0]],\n",
    "                                             mode='CONSTANT',\n",
    "                                             constant_values=0.0)\n",
    "\n",
    "                return padded_single_class\n",
    "\n",
    "            # Iterate filter_single_class() over all class indices.\n",
    "\n",
    "            filtered_single_classes = tf.map_fn(fn=lambda i: filter_single_class(i),\n",
    "                                    elems=tf.range(1,n_classes),\n",
    "                                    dtype=tf.float32,\n",
    "                                    parallel_iterations=128,\n",
    "                                    back_prop=False,\n",
    "                                    swap_memory=False,\n",
    "                                    infer_shape=True,\n",
    "                                    name='loop_over_classes')\n",
    "\n",
    "\n",
    "            # Concatenate the filtered results for all individual classes to one tensor.\n",
    "            #Union across all class_id to one Tensor\n",
    "            filtered_predictions = tf.reshape(tensor=filtered_single_classes, shape=(-1,6))\n",
    "\n",
    "            ''' \n",
    "            Perform top-k filtering for this batch item or pad it in case there are\n",
    "            fewer than `self.top_k` boxes left at this point. Either way, produce a\n",
    "            tensor of length `self.top_k`. By the time we return the final results tensor\n",
    "            for the whole batch, all batch items must have the same number of predicted\n",
    "            boxes so that the tensor dimensions are homogenous. If fewer than `self.top_k`\n",
    "            predictions are left after the filtering process above, we pad the missing\n",
    "            predictions with zeros as dummy entries\n",
    "            '''\n",
    "\n",
    "            def top_k():\n",
    "                return tf.gather(params=filtered_predictions,\n",
    "                                 indices=tf.nn.top_k(filtered_predictions[:, 1],k=self.tf_top_k, sorted=True).indices,\n",
    "                                 axis=0)\n",
    "\n",
    "            #We have a constant lenght equal self.top_k ,if we have fewer ,we add rows until we achive self.top_k length\n",
    "            def pad_and_top_k():\n",
    "                padded_predictions = tf.pad(tensor=filtered_predictions,\n",
    "                                            paddings=[[0, self.tf_top_k - tf.shape(filtered_predictions)[0]], [0, 0]],\n",
    "                                            mode='CONSTANT',constant_values=0.0)\n",
    "\n",
    "                return tf.gather(params=padded_predictions,\n",
    "                                 indices=tf.nn.top_k(padded_predictions[:, 1], k=self.tf_top_k, sorted=True).indices,\n",
    "                                 axis=0)\n",
    "\n",
    "            #Monitor lengt of n_boxes\n",
    "            top_k_boxes = tf.cond(tf.greater_equal(tf.shape(filtered_predictions)[0], self.tf_top_k), top_k, pad_and_top_k)\n",
    "\n",
    "            return top_k_boxes\n",
    "\n",
    "\n",
    "        # Iterate filter_predictions() over all batch items.\n",
    "        output_tensor = tf.map_fn(fn=lambda x: filter_predictions(x),\n",
    "                                  elems=y_pred,\n",
    "                                  dtype=None,\n",
    "                                  parallel_iterations=128,\n",
    "                                  back_prop=False,\n",
    "                                  swap_memory=False,\n",
    "                                  infer_shape=True,\n",
    "                                  name='loop_over_batch')\n",
    "\n",
    "        return output_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tesing algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=1\n",
    "n_boxes=350\n",
    "n_classes=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES=np.random.random_sample ((n_boxes,n_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOC=np.random.random_sample((n_boxes,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANCHOR=np.random.random_sample((n_boxes,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "VAR=ANCHOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "VAR[:,2:4].fill(0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((350, 20), (350, 4), (350, 4), (350, 4))"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CLASSES.shape,LOC.shape,ANCHOR.shape,VAR.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=np.concatenate([CLASSES,LOC,ANCHOR,VAR],axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=np.expand_dims(data,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 350, 32)"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tensor=tf.reshape(data,[-1,350,32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(1), Dimension(350), Dimension(32)])"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tensor.get_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "Transit= DecodeDetections(img_width=300,img_height=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Начало конвертации координат\n",
      "Конец конвертации\n",
      "Объявление функций конвертации : относительные и абсолютные\n",
      "Конец объявления функций конвертации : относительные и абсолютные\n",
      "Tf.cond\n",
      "Конец Tf.cond\n",
      "соединяем 20 классов и 4 координаты\n",
      "Задаем параметры\n"
     ]
    }
   ],
   "source": [
    "Test=Transit.call(y_pred=Tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tensor=tf.cast(Tensor,tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tf.float32"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(1), Dimension(200), Dimension(6)])"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Test.get_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
